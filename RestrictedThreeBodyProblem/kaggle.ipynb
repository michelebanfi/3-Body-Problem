{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "d3e6a32774afa719"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "9be582582be62e74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Classes",
   "id": "f0d4b80a6dc17d3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class LSTMReservoir(nn.Module):\n",
    "    def __init__(self, input_size, reservoir_size, output_size, num_layers=1, pred_len=1):\n",
    "        super(LSTMReservoir, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.output_size = output_size\n",
    "        self.pred_len = pred_len\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM as reservoir\n",
    "        self.lstm = nn.LSTM(input_size, reservoir_size, num_layers=num_layers, batch_first=True)\n",
    "        # freeze reservoir\n",
    "        for param in self.lstm.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Output weights\n",
    "        self.linear1 = nn.Linear(reservoir_size, 64)\n",
    "        self.linear2 = nn.Linear(64, output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    # LSTM forward pass\n",
    "    def forward(self, x):\n",
    "\n",
    "        # input shape: (amount of sequences, sequences length, dimensionality of problem)\n",
    "        input_len = x.size(1)\n",
    "        for i in range(self.pred_len):\n",
    "            # get the input and the previous outputs\n",
    "            input = x[:, i:i+input_len, :]\n",
    "\n",
    "            # the output will be just on the last hidden state\n",
    "            h, _ = self.lstm(input)\n",
    "            h = h[:, -1, :]\n",
    "            out = F.leaky_relu(self.linear1(h))\n",
    "            out = self.dropout(out)\n",
    "            out = self.linear2(out)\n",
    "\n",
    "            out = out.unsqueeze(1)\n",
    "            x = torch.cat((x, out), dim=1)\n",
    "\n",
    "        x = x[:, -self.pred_len:, :]\n",
    "        return x"
   ],
   "id": "bb9379cd4b977b87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, reservoir_size, output_size, num_layers=1, pred_len=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.output_size = output_size\n",
    "        self.pred_len = pred_len\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM as reservoir\n",
    "        self.lstm = nn.LSTM(input_size, reservoir_size, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # Output weights\n",
    "        self.linear1 = nn.Linear(reservoir_size, 64)\n",
    "        self.linear2 = nn.Linear(64, output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    # LSTM forward pass\n",
    "    def forward(self, x):\n",
    "\n",
    "        # input shape: (amount of sequences, sequences length, dimensionality of problem)\n",
    "        input_len = x.size(1)\n",
    "        for i in range(self.pred_len):\n",
    "            # get the input and the previous outputs\n",
    "            input = x[:, i:i+input_len, :]\n",
    "\n",
    "            # the output will be just on the last hidden state\n",
    "            h, _ = self.lstm(input)\n",
    "            h = h[:, -1, :]\n",
    "            out = F.leaky_relu(self.linear1(h))\n",
    "            out = self.dropout(out)\n",
    "            out = self.linear2(out)\n",
    "\n",
    "            out = out.unsqueeze(1)\n",
    "            x = torch.cat((x, out), dim=1)\n",
    "\n",
    "        x = x[:, -self.pred_len:, :]\n",
    "        return x"
   ],
   "id": "3a178914ad7f04d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate(num_epochs, criterion, optimizer, currentModel, train_dataloader, val_dataloader, device, scheduler=None):\n",
    "    train_losses = []\n",
    "    val_best_loss = np.inf\n",
    "    val_best_results = {'inputs':[], 'predictions':[], 'targets':[], 'losses':[]}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        running_loss = []\n",
    "        \n",
    "        val_results = {'inputs':[], 'predictions':[], 'targets':[], 'losses':[]}\n",
    "\n",
    "        # Train the model\n",
    "        currentModel.train()\n",
    "        for inputs, targets in train_dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = currentModel(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss.append(loss.item())\n",
    "\n",
    "        # Evaluate the model\n",
    "        currentModel.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in val_dataloader:\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                val_predictions = currentModel(val_inputs)\n",
    "                val_loss = criterion(val_predictions, val_targets)\n",
    "                val_results['inputs'].append(val_inputs)\n",
    "                val_results['predictions'].append(val_predictions)\n",
    "                val_results['targets'].append(val_targets)\n",
    "                val_results['losses'].append(val_loss.cpu().item())\n",
    "\n",
    "            val_mean_loss = np.mean(val_results[\"losses\"])\n",
    "            if val_mean_loss < val_best_loss:\n",
    "                val_best_loss = val_mean_loss\n",
    "                val_best_results = val_results\n",
    "                print(\"!!! BEST MODEL !!!\")\n",
    "\n",
    "        # end of epoch  \n",
    "        train_losses.append(np.mean(running_loss))\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {np.mean(running_loss):.3f}, Validation loss: {val_mean_loss:.3f}')\n",
    "        if scheduler is not None:\n",
    "            print(\"Learning rate: %.5f\" % scheduler.get_last_lr()[0])\n",
    "            scheduler.step() \n",
    "\n",
    "    return val_best_results, train_losses\n"
   ],
   "id": "8e23fc456cac4135"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Code",
   "id": "957f071828b39bf8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Working on:\", device)\n",
    "print(30*\"-\")\n",
    "\n",
    "# Define sequences length\n",
    "pred_len = 100\n",
    "input_len = 400\n",
    "\n",
    "# Define the model parameters\n",
    "io_size = 2\n",
    "reservoir_size = 8\n",
    "num_epochs = 20\n",
    "\n",
    "dimensionality = 2\n",
    "\n",
    "### LOAD DATA\n",
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "train_t, train_dataloader, val_t, val_dataloader = loadData(dimensionality, pred_len, input_len)\n",
    "print(\"Train batches:\", len(train_dataloader))\n",
    "print(\"Train input sequences:\", len(train_dataloader.dataset))\n",
    "print(\"Validation batches:\", len(val_dataloader))\n",
    "print(\"Validation input sequences:\", len(val_dataloader.dataset))\n",
    "print(30*\"-\")"
   ],
   "id": "330f210a913c140d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# init the models\n",
    "model = LSTMReservoir(io_size, reservoir_size, io_size, num_layers=1, pred_len=pred_len).to(device)\n",
    "modelBenchmark = LSTM(io_size, reservoir_size, io_size, num_layers=1, pred_len=pred_len).to(device)\n",
    "\n",
    "# NMSE weighted as criterion\n",
    "def NormalizedMeanSquaredError(y_pred, y_true):\n",
    "    device = y_pred.get_device()\n",
    "    if device == -1:\n",
    "        device = 'cpu'\n",
    "    pred_len = y_pred.size(1)\n",
    "    batch_size = y_pred.size(0)\n",
    "\n",
    "    squared_dist = torch.sum((y_true - y_pred)** 2, dim=2) # squared euclidean distances between predictions\n",
    "    true_squared_norm = torch.sum(y_true ** 2, dim=2)\n",
    "    nmse = squared_dist / true_squared_norm\n",
    "    # actual (from above) shape: (batch size, prediction length)\n",
    "    # as a neutral transformation for an overall error just take the mean on the prediction length and then on the batch size\n",
    "    # WEIGHTED\n",
    "    weights = torch.arange(start=1,end=pred_len+1,step=1).flip(dims=(0,)).square().to(device)\n",
    "    weights = weights/weights.sum()\n",
    "    aggregated_nmse = torch.zeros(batch_size)\n",
    "    for batch in range(batch_size):\n",
    "        aggregated_nmse[batch] = torch.dot(nmse[batch], weights)\n",
    "    # aggregated_nmse = torch.mean(torch.mean(nmse, dim=1), dim=0) # UNWEIGHTED\n",
    "    aggregated_nmse = torch.mean(aggregated_nmse, dim=0)\n",
    "    return aggregated_nmse"
   ],
   "id": "843dfbda89554545"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "401608f541117e7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### RESERVOIR\n",
    "# Define training setup\n",
    "# criterion\n",
    "criterion = NormalizedMeanSquaredError\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# scheduler\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "print(\"Reservoir training...\")\n",
    "# start counting the time\n",
    "start = time.time()\n",
    "# Train the model\n",
    "val_results, train_losses = (\n",
    "    evaluate(num_epochs, criterion, optimizer, model, train_dataloader, val_dataloader, device, scheduler))\n",
    "# stop counting the time\n",
    "end = time.time()\n",
    "print('Time elapsed: ', end - start, \"s\")\n",
    "print(30*\"-\")\n",
    "\n",
    "# plot training loss\n",
    "plt.plot(train_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training loss')\n",
    "plt.savefig('Media/3BP_training_loss.png')\n",
    "plt.close()\n",
    "    \n",
    "\n",
    "### BENCHMARK MODEL\n",
    "print(\"Benchmark training...\")\n",
    "# training setup\n",
    "# criterion\n",
    "criterion = NormalizedMeanSquaredError\n",
    "# optimizer\n",
    "optimizer = optim.Adam(modelBenchmark.parameters(), lr=0.001)\n",
    "# scheduler\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "# start counting the time\n",
    "start = time.time()\n",
    "# Train the benchmark model\n",
    "val_results_benchmark, train_losses_benchmark = (\n",
    "    evaluate(num_epochs, criterion, optimizer, modelBenchmark, train_dataloader, val_dataloader, device, scheduler))\n",
    "# stop counting the time\n",
    "end = time.time()\n",
    "print('Time elapsed: ', end - start, \"s\")\n",
    "print(30*\"-\")\n",
    "\n",
    "# plot training loss\n",
    "plt.plot(train_losses_benchmark)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training loss')\n",
    "plt.savefig('Media/3BP_training_loss_benchmark.png')\n",
    "plt.close()"
   ],
   "id": "e73efc72bac149f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plots",
   "id": "2dbcca8eef3a852c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plotting the predictions\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "how_many_plots = min(4, len(val_dataloader.dataset))\n",
    "n_sequences = len(val_dataloader.dataset)\n",
    "sequence_to_plot = torch.randint(0, n_sequences, (how_many_plots,))\n",
    "\n",
    "batch_size = val_results['targets'][0].size(0)\n",
    "batch_to_plot = torch.randint(0, batch_size, (how_many_plots,))\n",
    "\n",
    "for plot in range(how_many_plots - how_many_plots%2):\n",
    "    seq = sequence_to_plot[plot].item()\n",
    "    batch = batch_to_plot[plot].item()\n",
    "    # Plotting the predictions\n",
    "    plt.subplot(how_many_plots // 2, 2, plot + 1)\n",
    "    plt.plot(val_results['inputs'][seq][batch,:,0].cpu(), val_results['inputs'][seq][batch,:,1].cpu(), label='Input')\n",
    "    plt.plot(val_results['targets'][seq][batch,:,0].cpu(), val_results['targets'][seq][batch,:,1].cpu(), label='Target')\n",
    "    plt.plot(val_results['predictions'][seq][batch,:,0].cpu(), val_results['predictions'][seq][batch,:,1].cpu(), label='Predicted (Reservoir)')\n",
    "    plt.plot(val_results_benchmark['predictions'][seq][batch,:,0].cpu(), val_results_benchmark['predictions'][seq][batch,:,1].cpu(), label='Predicted (Benchmark)')\n",
    "    plt.xlabel('Time step')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "if diego:\n",
    "    plt.savefig('D:/File_vari/Scuola/Universita/Bicocca/Magistrale/AI4ST/23-24/II_semester/AIModels/3_Body_Problem/RestrictedThreeBodyProblem/Media/3BP_prediction.png')\n",
    "else:\n",
    "    plt.savefig('Media/3BP_prediction.png')\n",
    "plt.close()"
   ],
   "id": "28d5734d4f410a0e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
