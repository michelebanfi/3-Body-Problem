{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "d3e6a32774afa719"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "id": "9be582582be62e74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Classes",
   "id": "f0d4b80a6dc17d3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class LSTMReservoir(nn.Module):\n",
    "    def __init__(self, input_size, reservoir_size, output_size, num_layers=1, pred_len=1):\n",
    "        super(LSTMReservoir, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.output_size = output_size\n",
    "        self.pred_len = pred_len\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM as reservoir\n",
    "        self.lstm = nn.LSTM(input_size, reservoir_size, num_layers=num_layers, batch_first=True)\n",
    "        # freeze reservoir\n",
    "        for param in self.lstm.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Output weights\n",
    "        self.linear1 = nn.Linear(reservoir_size, 64)\n",
    "        self.linear2 = nn.Linear(64, output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    # LSTM forward pass\n",
    "    def forward(self, x):\n",
    "\n",
    "        # input shape: (amount of sequences, sequences length, dimensionality of problem)\n",
    "        input_len = x.size(1)\n",
    "        for i in range(self.pred_len):\n",
    "            # get the input and the previous outputs\n",
    "            input = x[:, i:i+input_len, :]\n",
    "\n",
    "            # the output will be just on the last hidden state\n",
    "            h, _ = self.lstm(input)\n",
    "            h = h[:, -1, :]\n",
    "            out = F.leaky_relu(self.linear1(h))\n",
    "            out = self.dropout(out)\n",
    "            out = self.linear2(out)\n",
    "\n",
    "            out = out.unsqueeze(1)\n",
    "            x = torch.cat((x, out), dim=1)\n",
    "\n",
    "        x = x[:, -self.pred_len:, :]\n",
    "        return x"
   ],
   "id": "bb9379cd4b977b87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, reservoir_size, output_size, num_layers=1, pred_len=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.output_size = output_size\n",
    "        self.pred_len = pred_len\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM as reservoir\n",
    "        self.lstm = nn.LSTM(input_size, reservoir_size, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # Output weights\n",
    "        self.linear1 = nn.Linear(reservoir_size, 64)\n",
    "        self.linear2 = nn.Linear(64, output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    # LSTM forward pass\n",
    "    def forward(self, x):\n",
    "\n",
    "        # input shape: (amount of sequences, sequences length, dimensionality of problem)\n",
    "        input_len = x.size(1)\n",
    "        for i in range(self.pred_len):\n",
    "            # get the input and the previous outputs\n",
    "            input = x[:, i:i+input_len, :]\n",
    "\n",
    "            # the output will be just on the last hidden state\n",
    "            h, _ = self.lstm(input)\n",
    "            h = h[:, -1, :]\n",
    "            out = F.leaky_relu(self.linear1(h))\n",
    "            out = self.dropout(out)\n",
    "            out = self.linear2(out)\n",
    "\n",
    "            out = out.unsqueeze(1)\n",
    "            x = torch.cat((x, out), dim=1)\n",
    "\n",
    "        x = x[:, -self.pred_len:, :]\n",
    "        return x"
   ],
   "id": "3a178914ad7f04d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Working on:\", device)\n",
    "print(30*\"-\")\n",
    "\n",
    "df = pd.read_csv(\"...\")\n",
    "data = torch.tensor(df[['x', 'y']].values)\n",
    "\n",
    "t = df['time'].values"
   ],
   "id": "f3ede970821cbf6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define sequences length\n",
    "pred_len = 100\n",
    "input_len = 400\n",
    "\n",
    "# Define the model parameters\n",
    "io_size = 2\n",
    "reservoir_size = 64\n",
    "num_epochs = 50\n",
    "\n",
    "### LOAD DATA\n",
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "train_t, train_dataloader, val_t, val_dataloader = loadData(data, t, pred_len, input_len)\n",
    "print(\"Train batches:\", len(train_dataloader))\n",
    "print(\"Train input sequences:\", len(train_dataloader.dataset))\n",
    "print(\"Validation batches:\", len(val_dataloader))\n",
    "print(\"Validation input sequences:\", len(val_dataloader.dataset))\n",
    "print(30*\"-\")"
   ],
   "id": "60294dbf690ede94"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# init the models\n",
    "model = LSTMReservoir(io_size, reservoir_size, io_size, num_layers=2, pred_len=pred_len).to(device)\n",
    "modelBenchmark = LSTM(io_size, reservoir_size, io_size, num_layers=2, pred_len=pred_len).to(device)"
   ],
   "id": "5809dfe9adf31f65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# NMSE weighted as criterion\n",
    "def NormalizedMeanSquaredError(y_pred, y_true):\n",
    "    device = y_pred.get_device()\n",
    "    pred_len = y_pred.size(1)\n",
    "    batch_size = y_pred.size(0)\n",
    "\n",
    "    squared_dist = torch.sum((y_true - y_pred)** 2, dim=2) # squared euclidean distances between predictions\n",
    "    true_squared_norm = torch.sum(y_true ** 2, dim=2)\n",
    "    nmse = squared_dist / true_squared_norm\n",
    "    # actual (from above) shape: (batch size, prediction length)\n",
    "    # as a neutral transformation for an overall error just take the mean on the prediction length and then on the batch size\n",
    "    # WEIGHTED\n",
    "    weights = torch.arange(start=1,end=pred_len+1,step=1).flip(dims=(0,)).to(device)\n",
    "    weights = weights/weights.sum()\n",
    "    aggregated_nmse = torch.zeros(batch_size)\n",
    "    for batch in range(batch_size):\n",
    "        aggregated_nmse[batch] = torch.dot(nmse[batch], weights)\n",
    "    # aggregated_nmse = torch.mean(torch.mean(nmse, dim=1), dim=0) # UNWEIGHTED\n",
    "    aggregated_nmse = torch.mean(aggregated_nmse, dim=0)\n",
    "    return aggregated_nmse\n"
   ],
   "id": "c3fa93a672a15c3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### RESERVOIR\n",
    "# Define training setup\n",
    "# criterion\n",
    "criterion = NormalizedMeanSquaredError\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# scheduler\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.2)\n",
    "print(\"Reservoir training...\")\n",
    "# start counting the time\n",
    "start = time.time()\n",
    "# Train the model\n",
    "val_results, train_losses = (\n",
    "    evaluate(num_epochs, criterion, optimizer, model, train_dataloader, val_dataloader, device, scheduler))\n",
    "# stop counting the time\n",
    "end = time.time()\n",
    "print('Time elapsed: ', end - start, \"s\")\n",
    "print(30*\"-\")\n",
    "\n",
    "### BENCHMARK MODEL\n",
    "print(\"Benchmark training...\")\n",
    "# training setup\n",
    "# criterion\n",
    "criterion = NormalizedMeanSquaredError\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# scheduler\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.2)\n",
    "# start counting the time\n",
    "start = time.time()\n",
    "# Train the benchmark model\n",
    "val_results_benchmark, train_losses_benchmark = (\n",
    "    evaluate(num_epochs, criterion, optimizer, modelBenchmark, train_dataloader, val_dataloader, device, scheduler))\n",
    "# stop counting the time\n",
    "end = time.time()\n",
    "print('Time elapsed: ', end - start, \"s\")\n",
    "print(30*\"-\")"
   ],
   "id": "c7594108fefb2273"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
