{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "d3e6a32774afa719"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "9be582582be62e74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Classes",
   "id": "f0d4b80a6dc17d3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ESNReservoir(nn.Module):\n",
    "    def __init__(self, input_size, reservoir_size, output_size, pred_len, spectral_radius=0.9, sparsity=0.1):\n",
    "        super(ESNReservoir, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.output_size = output_size\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "        # Input weights\n",
    "        self.Win = nn.Parameter(torch.randn(reservoir_size, input_size), requires_grad=False)\n",
    "\n",
    "        # Reservoir weights\n",
    "        self.W = nn.Parameter(torch.randn(reservoir_size, reservoir_size), requires_grad=False)\n",
    "\n",
    "        # Output weights\n",
    "        self.Wout = nn.Linear(reservoir_size, output_size)\n",
    "\n",
    "        # Adjust spectral radius\n",
    "        self.W.data *= spectral_radius / torch.max(torch.abs(torch.linalg.eigvals(self.W.data)))\n",
    "\n",
    "        # Apply sparsity\n",
    "        mask = (torch.rand(reservoir_size, reservoir_size) < sparsity).float()\n",
    "        self.W.data *= mask\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        h = torch.zeros(1, self.reservoir_size).to(device)\n",
    "        input_len = x.size(1)\n",
    "\n",
    "        for t in range(input_len + self.pred_len-1):\n",
    "            # take single point\n",
    "            input = x[0, t, :]\n",
    "            input = input.unsqueeze(0)\n",
    "            # get hidden state from the point extracted and the previous hidden state\n",
    "            h = torch.tanh(self.Win @ input.T + self.W @ h.T).T\n",
    "            # if the time reached the input lenght we start concatenating outputs in order to pick them in the next round\n",
    "            if t >= input_len-1:\n",
    "                # calculate the output\n",
    "                output = self.Wout(h)\n",
    "                output = output.unsqueeze(1)\n",
    "                x = torch.cat((x, output), dim=1)\n",
    "\n",
    "        return x[:, -self.pred_len:, :]"
   ],
   "id": "bb9379cd4b977b87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, reservoir_size, output_size, num_layers=1, pred_len=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.output_size = output_size\n",
    "        self.pred_len = pred_len\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM as reservoir\n",
    "        self.lstm = nn.LSTM(input_size, reservoir_size, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # Output weights\n",
    "        self.linear1 = nn.Linear(reservoir_size, 64)\n",
    "        self.linear2 = nn.Linear(64, output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    # LSTM forward pass\n",
    "    def forward(self, x):\n",
    "\n",
    "        # input shape: (amount of sequences, sequences length, dimensionality of problem)\n",
    "        input_len = x.size(1)\n",
    "        for i in range(self.pred_len):\n",
    "            # get the input and the previous outputs\n",
    "            input = x[:, i:i+input_len, :]\n",
    "\n",
    "            # the output will be just on the last hidden state\n",
    "            h, _ = self.lstm(input)\n",
    "            h = h[:, -1, :]\n",
    "            out = F.leaky_relu(self.linear1(h))\n",
    "            out = self.dropout(out)\n",
    "            out = self.linear2(out)\n",
    "\n",
    "            out = out.unsqueeze(1)\n",
    "            x = torch.cat((x, out), dim=1)\n",
    "\n",
    "        x = x[:, -self.pred_len:, :]\n",
    "        return x"
   ],
   "id": "3a178914ad7f04d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate(num_epochs, criterion, optimizer, currentModel, train_dataloader, val_dataloader, device, scheduler=None):\n",
    "    train_losses = []\n",
    "    val_best_loss = np.inf\n",
    "    val_best_results = {'inputs':[], 'predictions':[], 'targets':[], 'losses':[]}\n",
    "    max_patience = 6\n",
    "    patience = max_patience\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        ## begin of epoch\n",
    "        print(\"\")\n",
    "        print(5*\">\", \"New epoch\", 5*\"<\")\n",
    "        running_loss = []\n",
    "        val_results = {'inputs':[], 'predictions':[], 'targets':[], 'losses':[]}\n",
    "        patience-=1\n",
    "\n",
    "        ## epoch\n",
    "        # Train the model\n",
    "        currentModel.train()\n",
    "        for inputs, targets in train_dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = currentModel(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "            running_loss.append(loss.item())\n",
    "\n",
    "        # Evaluate the model\n",
    "        currentModel.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in val_dataloader:\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                val_predictions = currentModel(val_inputs)\n",
    "                val_loss = criterion(val_predictions, val_targets)\n",
    "                val_results['inputs'].append(val_inputs)\n",
    "                val_results['predictions'].append(val_predictions)\n",
    "                val_results['targets'].append(val_targets)\n",
    "                val_results['losses'].append(val_loss.cpu().item())\n",
    "\n",
    "            val_mean_loss = np.mean(val_results[\"losses\"])\n",
    "            if val_best_loss - val_mean_loss > 1e-4: # if the best model is sensibly worst then the current\n",
    "                # save best model results\n",
    "                val_best_loss = val_mean_loss\n",
    "                val_best_results = val_results \n",
    "                # restore patience\n",
    "                patience = max_patience\n",
    "                print(\"!!! BEST MODEL !!!\")\n",
    "\n",
    "        ## end of epoch  \n",
    "        # show info\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {np.mean(running_loss):.3f}, Validation loss: {val_mean_loss:.3f}')\n",
    "        # scheduler\n",
    "        if scheduler is not None:\n",
    "            print(\"Learning rate: %.5f\" % scheduler.get_last_lr()[0])\n",
    "            scheduler.step() \n",
    "        # patience  \n",
    "        if patience == 0:\n",
    "            print(\"Ran out of patience\")\n",
    "            break\n",
    "\n",
    "    return val_best_results, train_losses"
   ],
   "id": "8e23fc456cac4135"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def loadData(dimensionality, pred_len, input_len, train_batch_size=1, val_batch_size=1, file=\"3BP\"):\n",
    "    num_files = 3\n",
    "\n",
    "    train_sequences = torch.zeros(size=(1, input_len, dimensionality), dtype=torch.float32)\n",
    "    train_targets = torch.zeros(size=(1, pred_len, dimensionality), dtype=torch.float32)\n",
    "    val_sequences = torch.zeros(size=(1, input_len, dimensionality), dtype=torch.float32)\n",
    "    val_targets = torch.zeros(size=(1, pred_len, dimensionality), dtype=torch.float32)\n",
    "\n",
    "\n",
    "    for i in range(0, num_files):\n",
    "\n",
    "        df = pd.read_csv(f\"/kaggle/input/r3bpdataset/{file}_{i}.csv\")\n",
    "\n",
    "        if file == \"3BP\":\n",
    "            variables = ['x', 'y',]\n",
    "        elif file == \"lorenz\":\n",
    "            variables = ['x', 'y', 'z']\n",
    "\n",
    "        data = torch.tensor(df[variables].values)\n",
    "        t = df['time'].values\n",
    "\n",
    "        # Split the data into training and validation sets\n",
    "        train_data, val_data = train_test_split(data, test_size=0.2, shuffle=False)\n",
    "        train_t, val_t = train_test_split(t, test_size=0.2, shuffle=False)\n",
    "\n",
    "        # Function to create inputs\n",
    "        def create_sequences(data, pred_len, input_len, n_samples=100): # data: (points, dimension)\n",
    "            inputs = torch.zeros(size=(1, input_len, data.size(1)), dtype=torch.float32) # to concat\n",
    "            targets = torch.zeros(size=(1, pred_len, data.size(1)), dtype=torch.float32) # to concat\n",
    "\n",
    "            # generate n starting points to sample n subsequences\n",
    "            n_data = data.size(0)\n",
    "            perm = torch.randperm(n_data - pred_len - input_len)\n",
    "            starting_points = perm[:n_samples]\n",
    "            for start_input in starting_points: #range(0, n_data - pred_len, input_len + pred_len):\n",
    "                #if start_input + input_len + pred_len >= n_data: break # cut tail that do not fit the size of data\n",
    "                \n",
    "\n",
    "                new_input = data[start_input:start_input + input_len].unsqueeze(0)\n",
    "                inputs = torch.cat((inputs, new_input), dim=0)\n",
    "\n",
    "                new_target = data[start_input + input_len:start_input + pred_len + input_len].unsqueeze(0)\n",
    "                targets = torch.cat((targets, new_target))\n",
    "\n",
    "            # remove first entry -> zeros by initialization\n",
    "            inputs = inputs[1:, :, :].float()\n",
    "            targets = targets[1:, :, :].float()\n",
    "            return inputs, targets\n",
    "\n",
    "        # Create sequences for training and validation\n",
    "        train_seq, train_tar = create_sequences(train_data, pred_len, input_len, n_samples=10)\n",
    "        val_seq, val_tar = create_sequences(val_data, pred_len, input_len, n_samples=10)\n",
    "\n",
    "        # Concatenate the sequences\n",
    "        train_sequences = torch.cat((train_sequences, train_seq), dim=0)\n",
    "        train_targets = torch.cat((train_targets, train_tar), dim=0)\n",
    "        val_sequences = torch.cat((val_sequences, val_seq), dim=0)\n",
    "        val_targets = torch.cat((val_targets, val_tar), dim=0)\n",
    "\n",
    "    # remove first entry -> zeros by initialization\n",
    "    train_sequences = train_sequences[1:, :, :]\n",
    "    train_targets = train_targets[1:, :, :]\n",
    "    val_sequences = val_sequences[1:, :, :]\n",
    "    val_targets = val_targets[1:, :, :]\n",
    "\n",
    "    # Create DataLoader for batching\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_sequences, train_targets)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "    val_dataset = torch.utils.data.TensorDataset(val_sequences, val_targets)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=val_batch_size, shuffle=True)\n",
    "\n",
    "    return train_t, train_dataloader, val_t, val_dataloader"
   ],
   "id": "dacc5c48a01cfaa2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Code",
   "id": "957f071828b39bf8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Working on:\", device)\n",
    "print(30*\"-\")\n",
    "\n",
    "# Define sequences length\n",
    "pred_len = 100\n",
    "input_len = 400\n",
    "\n",
    "# Define the model parameters\n",
    "io_size = 2\n",
    "reservoir_size = 256\n",
    "num_epochs = 20\n",
    "\n",
    "### LOAD DATA\n",
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "train_t, train_dataloader, val_t, val_dataloader = loadData(io_size, pred_len, input_len, file=\"3BP\")\n",
    "print(\"Train batches:\", len(train_dataloader))\n",
    "print(\"Train input sequences:\", len(train_dataloader.dataset))\n",
    "print(\"Validation batches:\", len(val_dataloader))\n",
    "print(\"Validation input sequences:\", len(val_dataloader.dataset))\n",
    "print(30*\"-\")"
   ],
   "id": "330f210a913c140d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# init the models\n",
    "model = ESNReservoir(io_size, reservoir_size, io_size, pred_len=pred_len).to(device)\n",
    "modelBenchmark = LSTM(io_size, reservoir_size, io_size, num_layers=1, pred_len=pred_len).to(device)\n",
    "\n",
    "# NMSE weighted as criterion\n",
    "def NormalizedMeanSquaredError(y_pred, y_true):\n",
    "    device = y_pred.get_device()\n",
    "    if device == -1:\n",
    "        device = 'cpu'\n",
    "    pred_len = y_pred.size(1)\n",
    "    batch_size = y_pred.size(0)\n",
    "\n",
    "    squared_dist = torch.sum((y_true - y_pred)** 2, dim=2) # squared euclidean distances between predictions\n",
    "    true_squared_norm = torch.sum(y_true ** 2, dim=2)\n",
    "    nmse = squared_dist / true_squared_norm\n",
    "    # actual (from above) shape: (batch size, prediction length)\n",
    "    # WEIGHTED\n",
    "    base = torch.tensor(2, dtype=torch.float32)\n",
    "    weights = base.pow(-torch.arange(start=1,end=pred_len+1,step=1)).to(device)\n",
    "    weights = weights/weights.sum()\n",
    "    aggregated_nmse = torch.zeros(batch_size)\n",
    "    for batch in range(batch_size):\n",
    "        aggregated_nmse[batch] = torch.dot(nmse[batch], weights)\n",
    "    # UNWEIGHTED\n",
    "    # aggregated_nmse = torch.mean(torch.mean(nmse, dim=1), dim=0) \n",
    "    aggregated_nmse = torch.mean(aggregated_nmse, dim=0)\n",
    "    return aggregated_nmse"
   ],
   "id": "843dfbda89554545"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "401608f541117e7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### RESERVOIR\n",
    "# Define training setup\n",
    "criterion = NormalizedMeanSquaredError\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# scheduler\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "print(\"Reservoir training...\")\n",
    "# start counting the time\n",
    "start = time.time()\n",
    "# Train the model\n",
    "val_results, train_losses = (\n",
    "    evaluate(num_epochs, criterion, optimizer, model, train_dataloader, val_dataloader, device, scheduler))\n",
    "# stop counting the time\n",
    "end = time.time()\n",
    "print('Time elapsed: ', end - start, \"s\")\n",
    "print(30*\"-\")\n",
    "\n",
    "### BENCHMARK MODEL\n",
    "print(\"Benchmark training...\")\n",
    "# training setup\n",
    "# criterion\n",
    "criterion = NormalizedMeanSquaredError\n",
    "# optimizer\n",
    "optimizer = optim.Adam(modelBenchmark.parameters(), lr=0.001)\n",
    "# scheduler\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "# start counting the time\n",
    "start = time.time()\n",
    "# Train the benchmark model\n",
    "val_results_benchmark, train_losses_benchmark = (\n",
    "    evaluate(num_epochs, criterion, optimizer, modelBenchmark, train_dataloader, val_dataloader, device, scheduler))\n",
    "# stop counting the time\n",
    "end = time.time()\n",
    "print('Time elapsed: ', end - start, \"s\")\n",
    "print(30*\"-\")\n",
    "\n",
    "# plot training loss\n",
    "plt.plot(train_losses_benchmark)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training loss')\n",
    "plt.savefig('Media/3BP_training_loss_benchmark.png')\n",
    "plt.close()"
   ],
   "id": "e73efc72bac149f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plots",
   "id": "2dbcca8eef3a852c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### PLOTS\n",
    "# Plotting the predictions\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "how_many_plots = min(4, len(val_dataloader.dataset))\n",
    "n_sequences = len(val_dataloader.dataset)\n",
    "sequence_to_plot = torch.randint(0, n_sequences, (how_many_plots,))\n",
    "\n",
    "batch_size = val_results['targets'][0].size(0)\n",
    "batch_to_plot = torch.randint(0, batch_size, (how_many_plots,))\n",
    "\n",
    "for plot in range(how_many_plots - how_many_plots%2):\n",
    "    seq = sequence_to_plot[plot].item()\n",
    "    batch = batch_to_plot[plot].item()\n",
    "    # Plotting the predictions\n",
    "    plt.subplot(how_many_plots // 2, 2, plot + 1)\n",
    "    plt.plot(val_results['inputs'][seq][batch,:,0].cpu(), val_results['inputs'][seq][batch,:,1].cpu(), label='Input')\n",
    "    plt.plot(val_results['targets'][seq][batch,:,0].cpu(), val_results['targets'][seq][batch,:,1].cpu(), label='Target')\n",
    "    plt.plot(val_results['predictions'][seq][batch,:,0].cpu(), val_results['predictions'][seq][batch,:,1].cpu(), label='Predicted (Reservoir)')\n",
    "    plt.plot(val_results_benchmark['predictions'][seq][batch,:,0].cpu(), val_results_benchmark['predictions'][seq][batch,:,1].cpu(), label='Predicted (Benchmark)')\n",
    "    plt.xlabel('Time step')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Media/3BP_prediction.png')\n",
    "plt.close()"
   ],
   "id": "28d5734d4f410a0e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
